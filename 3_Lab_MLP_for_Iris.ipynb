{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "3-Lab-MLP for Iris.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TranToQuePhuong/AI_Lab08/blob/master/3_Lab_MLP_for_Iris.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gvKshvFzQorr"
      },
      "source": [
        "# Multilayer Perceptron for Iris dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TzdCpFLTo_X",
        "colab_type": "text"
      },
      "source": [
        "- Nguyễn Hữu Vũ \n",
        "- Nhóm nghiên cứu về AI đại học Bách Khoa Tp. Hồ Chí Minh"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5GW8ihpTo_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hfaj3L3sTo_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the iris dataset\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "# Create our X and y data\n",
        "X = iris.data\n",
        "y = iris.target"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEKdPsJdTo_g",
        "colab_type": "text"
      },
      "source": [
        "## 1) Khám phá dữ liệu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJcROtT7To_h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "753e4642-29b4-4d11-9e67-cbc6945c7889"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3Q-OYT_To_p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8628e7fe-d595-4c82-9dad-2faac2771fd2"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oi22PFWKTo_1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "222e31b9-7695-4209-b2ce-ac0c9110ba3d"
      },
      "source": [
        "X[:5]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.1, 3.5, 1.4, 0.2],\n",
              "       [4.9, 3. , 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.3, 0.2],\n",
              "       [4.6, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.6, 1.4, 0.2]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3_AsVxuTo_5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "535eed50-bd67-467c-9a69-cc77034f3aba"
      },
      "source": [
        "# View the first five observations of our y data\n",
        "y[:5]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnOdL66dTo_9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMtzofzmTpAD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split the data into 70% training data and 30% test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61YN1beTTpAK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "a7104118-f219-4bcd-c122-54c446d200ce"
      },
      "source": [
        "X_train[:5]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.9, 2.5, 4.5, 1.7],\n",
              "       [5.5, 2.5, 4. , 1.3],\n",
              "       [5.1, 2.5, 3. , 1.1],\n",
              "       [4.9, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.4, 1.5, 0.2]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRzZFTWnTpAT",
        "colab_type": "text"
      },
      "source": [
        "## 2) Chuẩn bị dữ liệu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "rOkk-YmBTpAT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "17acd83d-5779-486b-e6db-68f90008f4d4"
      },
      "source": [
        "# Train the scaler, which standarizes all the features to have mean=0 and unit variance\n",
        "sc = StandardScaler()\n",
        "sc.fit(X_train)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StandardScaler(copy=True, with_mean=True, with_std=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ha0kQV2JTpAW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Apply the scaler to the X training data\n",
        "X_train_std = sc.transform(X_train)\n",
        "\n",
        "# Apply the SAME scaler to the X test data\n",
        "X_test_std = sc.transform(X_test)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XDms7eHTpAa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "4cf74f41-db34-41ce-e9e5-adf4f8cc48a8"
      },
      "source": [
        "X_train_std[:5]"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.21660018, -1.26092449,  0.4230325 ,  0.67778903],\n",
              "       [-0.44396095, -1.26092449,  0.1308061 ,  0.13555781],\n",
              "       [-0.95905377, -1.26092449, -0.4536467 , -0.13555781],\n",
              "       [-1.21660018,  0.10165258, -1.3303259 , -1.35557806],\n",
              "       [-1.08782697,  0.78294111, -1.3303259 , -1.35557806]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6T9OF4G8TpAc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "fe9ac2eb-97a0-4da8-8aae-a03925d7c72e"
      },
      "source": [
        "X_test_std[:5]"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.47414659,  0.32874875, -1.27188062, -1.35557806],\n",
              "       [-1.47414659,  0.32874875, -1.44721646, -1.35557806],\n",
              "       [-0.18641454,  1.69132582, -1.21343534, -1.22002025],\n",
              "       [ 0.45745148, -0.57963596,  0.59836835,  0.81334684],\n",
              "       [ 1.74518352, -0.1254436 ,  1.18282115,  0.54223122]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fQh2Xl4TpAg",
        "colab_type": "text"
      },
      "source": [
        "## 3) Xây dựng model Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6sWYgAFTpAg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a perceptron object with the parameters: 40 iterations (epochs) over the data, and a learning rate of 0.1\n",
        "ppn = Perceptron(n_iter_no_change=40, eta0=0.1, random_state=0)\n",
        "\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "dX7XX9NETpAl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "276a36f5-c6c5-4468-8129-57c57c3bfa19"
      },
      "source": [
        "\n",
        "# Train the perceptron\n",
        "ppn.fit(X_train_std, y_train)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=0.1,\n",
              "           fit_intercept=True, max_iter=1000, n_iter_no_change=40, n_jobs=None,\n",
              "           penalty=None, random_state=0, shuffle=True, tol=0.001,\n",
              "           validation_fraction=0.1, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BNqZjaDTpAo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "95fb2836-8c06-4512-d957-4ed22ca7b613"
      },
      "source": [
        "#The actual number of iterations to reach the stopping criterion. For multiclass fits, it is the maximum over every binary fit.\n",
        "ppn.n_iter_ "
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ET1zMAp_TpAq",
        "colab_type": "text"
      },
      "source": [
        "##### Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "vMblprEyTpAr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3a99a21b-7e5a-4ab3-d604-6f9e6f4c07c4"
      },
      "source": [
        "# Apply the trained perceptron on the X data to make predicts for the y test data\n",
        "y_pred = ppn.predict(X_test_std)\n",
        "y_pred"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
              "       1, 1, 2, 1, 2, 2, 2, 2, 1, 2, 0, 2, 0, 1, 2, 2, 1, 2, 2, 0, 0, 2,\n",
              "       2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6RjbpuRTpAu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "364c1042-e468-4a6a-ea1b-c55bb6dd67b0"
      },
      "source": [
        "# View the accuracy of the model, which is: 1 - (observations predicted wrong / total observations)\n",
        "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.87\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzhxGK0zTpAy",
        "colab_type": "text"
      },
      "source": [
        "## 4) Xây dựng model MLPClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tm5OP0KiTpAy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "clf = MLPClassifier(hidden_layer_sizes=(8,5 ), activation='tanh', solver='sgd', \n",
        "                    alpha=0.0000001, batch_size=4, learning_rate='constant', learning_rate_init=0.005, \n",
        "                    power_t=0.5, max_iter=500, shuffle=True, random_state=11, tol=0.00001, \n",
        "                    verbose=True, warm_start=False, momentum=0.8, nesterovs_momentum=True, \n",
        "                    early_stopping=False, validation_fraction=0.2, \n",
        "                    beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "WeKsMePWTpA2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e1c9ed8b-4a80-4704-acd1-25ca50b193d5"
      },
      "source": [
        "\n",
        "# Train the perceptron\n",
        "clf.fit(X_train_std, y_train)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1.07716441\n",
            "Iteration 2, loss = 0.85922656\n",
            "Iteration 3, loss = 0.72572601\n",
            "Iteration 4, loss = 0.63832049\n",
            "Iteration 5, loss = 0.57435686\n",
            "Iteration 6, loss = 0.52922345\n",
            "Iteration 7, loss = 0.49391923\n",
            "Iteration 8, loss = 0.46494054\n",
            "Iteration 9, loss = 0.43861982\n",
            "Iteration 10, loss = 0.41278833\n",
            "Iteration 11, loss = 0.38865385\n",
            "Iteration 12, loss = 0.36634762\n",
            "Iteration 13, loss = 0.34367166\n",
            "Iteration 14, loss = 0.32080249\n",
            "Iteration 15, loss = 0.29977307\n",
            "Iteration 16, loss = 0.28053218\n",
            "Iteration 17, loss = 0.26140939\n",
            "Iteration 18, loss = 0.24518720\n",
            "Iteration 19, loss = 0.23104921\n",
            "Iteration 20, loss = 0.21402383\n",
            "Iteration 21, loss = 0.20073701\n",
            "Iteration 22, loss = 0.19011813\n",
            "Iteration 23, loss = 0.18072813\n",
            "Iteration 24, loss = 0.16771376\n",
            "Iteration 25, loss = 0.15837190\n",
            "Iteration 26, loss = 0.15124634\n",
            "Iteration 27, loss = 0.14250117\n",
            "Iteration 28, loss = 0.14000787\n",
            "Iteration 29, loss = 0.12932775\n",
            "Iteration 30, loss = 0.12318969\n",
            "Iteration 31, loss = 0.11758731\n",
            "Iteration 32, loss = 0.11364781\n",
            "Iteration 33, loss = 0.10799746\n",
            "Iteration 34, loss = 0.10412910\n",
            "Iteration 35, loss = 0.10106547\n",
            "Iteration 36, loss = 0.09620269\n",
            "Iteration 37, loss = 0.09291735\n",
            "Iteration 38, loss = 0.09030894\n",
            "Iteration 39, loss = 0.09416201\n",
            "Iteration 40, loss = 0.09047348\n",
            "Iteration 41, loss = 0.08176896\n",
            "Iteration 42, loss = 0.08022011\n",
            "Iteration 43, loss = 0.07704536\n",
            "Iteration 44, loss = 0.07618147\n",
            "Iteration 45, loss = 0.07418015\n",
            "Iteration 46, loss = 0.07088462\n",
            "Iteration 47, loss = 0.06993444\n",
            "Iteration 48, loss = 0.06780934\n",
            "Iteration 49, loss = 0.06856752\n",
            "Iteration 50, loss = 0.06560264\n",
            "Iteration 51, loss = 0.06593702\n",
            "Iteration 52, loss = 0.06121550\n",
            "Iteration 53, loss = 0.06081467\n",
            "Iteration 54, loss = 0.05909695\n",
            "Iteration 55, loss = 0.05720221\n",
            "Iteration 56, loss = 0.05676334\n",
            "Iteration 57, loss = 0.05571973\n",
            "Iteration 58, loss = 0.05463853\n",
            "Iteration 59, loss = 0.05300069\n",
            "Iteration 60, loss = 0.05183025\n",
            "Iteration 61, loss = 0.05177120\n",
            "Iteration 62, loss = 0.05000944\n",
            "Iteration 63, loss = 0.05037256\n",
            "Iteration 64, loss = 0.04775487\n",
            "Iteration 65, loss = 0.04731122\n",
            "Iteration 66, loss = 0.05008459\n",
            "Iteration 67, loss = 0.04625738\n",
            "Iteration 68, loss = 0.04505204\n",
            "Iteration 69, loss = 0.04543146\n",
            "Iteration 70, loss = 0.04386881\n",
            "Iteration 71, loss = 0.04244378\n",
            "Iteration 72, loss = 0.04341833\n",
            "Iteration 73, loss = 0.04236380\n",
            "Iteration 74, loss = 0.04207046\n",
            "Iteration 75, loss = 0.04051392\n",
            "Iteration 76, loss = 0.03905203\n",
            "Iteration 77, loss = 0.03952030\n",
            "Iteration 78, loss = 0.03905822\n",
            "Iteration 79, loss = 0.03723085\n",
            "Iteration 80, loss = 0.03726313\n",
            "Iteration 81, loss = 0.03671113\n",
            "Iteration 82, loss = 0.03594465\n",
            "Iteration 83, loss = 0.03517445\n",
            "Iteration 84, loss = 0.03676236\n",
            "Iteration 85, loss = 0.03499977\n",
            "Iteration 86, loss = 0.03292784\n",
            "Iteration 87, loss = 0.03353768\n",
            "Iteration 88, loss = 0.03377480\n",
            "Iteration 89, loss = 0.03203757\n",
            "Iteration 90, loss = 0.03370675\n",
            "Iteration 91, loss = 0.03278019\n",
            "Iteration 92, loss = 0.03093302\n",
            "Iteration 93, loss = 0.03138506\n",
            "Iteration 94, loss = 0.02974920\n",
            "Iteration 95, loss = 0.03003664\n",
            "Iteration 96, loss = 0.03012137\n",
            "Iteration 97, loss = 0.03003742\n",
            "Iteration 98, loss = 0.02902512\n",
            "Iteration 99, loss = 0.02894254\n",
            "Iteration 100, loss = 0.02842949\n",
            "Iteration 101, loss = 0.02929717\n",
            "Iteration 102, loss = 0.02840632\n",
            "Iteration 103, loss = 0.02846825\n",
            "Iteration 104, loss = 0.02656014\n",
            "Iteration 105, loss = 0.02616638\n",
            "Iteration 106, loss = 0.02664634\n",
            "Iteration 107, loss = 0.02570115\n",
            "Iteration 108, loss = 0.02689534\n",
            "Iteration 109, loss = 0.02563705\n",
            "Iteration 110, loss = 0.02473423\n",
            "Iteration 111, loss = 0.02490009\n",
            "Iteration 112, loss = 0.02438307\n",
            "Iteration 113, loss = 0.02506170\n",
            "Iteration 114, loss = 0.02491893\n",
            "Iteration 115, loss = 0.02439945\n",
            "Iteration 116, loss = 0.02407538\n",
            "Iteration 117, loss = 0.02310473\n",
            "Iteration 118, loss = 0.02370973\n",
            "Iteration 119, loss = 0.02381660\n",
            "Iteration 120, loss = 0.02317994\n",
            "Iteration 121, loss = 0.02310946\n",
            "Iteration 122, loss = 0.02265882\n",
            "Iteration 123, loss = 0.02343854\n",
            "Iteration 124, loss = 0.02204015\n",
            "Iteration 125, loss = 0.02341691\n",
            "Iteration 126, loss = 0.02141055\n",
            "Iteration 127, loss = 0.02204213\n",
            "Iteration 128, loss = 0.02107252\n",
            "Iteration 129, loss = 0.02100299\n",
            "Iteration 130, loss = 0.02152701\n",
            "Iteration 131, loss = 0.02140323\n",
            "Iteration 132, loss = 0.02339964\n",
            "Iteration 133, loss = 0.02086902\n",
            "Iteration 134, loss = 0.02067851\n",
            "Iteration 135, loss = 0.02690926\n",
            "Iteration 136, loss = 0.01973886\n",
            "Iteration 137, loss = 0.01996208\n",
            "Iteration 138, loss = 0.01952393\n",
            "Iteration 139, loss = 0.01967557\n",
            "Iteration 140, loss = 0.01995945\n",
            "Iteration 141, loss = 0.01919865\n",
            "Iteration 142, loss = 0.01837745\n",
            "Iteration 143, loss = 0.01839362\n",
            "Iteration 144, loss = 0.01879683\n",
            "Iteration 145, loss = 0.01850278\n",
            "Iteration 146, loss = 0.01874522\n",
            "Iteration 147, loss = 0.01939346\n",
            "Iteration 148, loss = 0.01865473\n",
            "Iteration 149, loss = 0.01870205\n",
            "Iteration 150, loss = 0.02330035\n",
            "Iteration 151, loss = 0.01840163\n",
            "Iteration 152, loss = 0.01755012\n",
            "Iteration 153, loss = 0.01715680\n",
            "Iteration 154, loss = 0.01718649\n",
            "Iteration 155, loss = 0.01849489\n",
            "Iteration 156, loss = 0.01686974\n",
            "Iteration 157, loss = 0.01772783\n",
            "Iteration 158, loss = 0.01626133\n",
            "Iteration 159, loss = 0.01697431\n",
            "Iteration 160, loss = 0.01677585\n",
            "Iteration 161, loss = 0.01679654\n",
            "Iteration 162, loss = 0.01726050\n",
            "Iteration 163, loss = 0.01665304\n",
            "Iteration 164, loss = 0.01666368\n",
            "Iteration 165, loss = 0.01694478\n",
            "Iteration 166, loss = 0.01589009\n",
            "Iteration 167, loss = 0.01528524\n",
            "Iteration 168, loss = 0.01469587\n",
            "Iteration 169, loss = 0.01642624\n",
            "Iteration 170, loss = 0.01527544\n",
            "Iteration 171, loss = 0.01531915\n",
            "Iteration 172, loss = 0.01486461\n",
            "Iteration 173, loss = 0.01694498\n",
            "Iteration 174, loss = 0.01541266\n",
            "Iteration 175, loss = 0.01475670\n",
            "Iteration 176, loss = 0.01527860\n",
            "Iteration 177, loss = 0.01512140\n",
            "Iteration 178, loss = 0.01526926\n",
            "Iteration 179, loss = 0.01415927\n",
            "Iteration 180, loss = 0.01624327\n",
            "Iteration 181, loss = 0.01569910\n",
            "Iteration 182, loss = 0.01432794\n",
            "Iteration 183, loss = 0.01465718\n",
            "Iteration 184, loss = 0.01489086\n",
            "Iteration 185, loss = 0.01501570\n",
            "Iteration 186, loss = 0.01758374\n",
            "Iteration 187, loss = 0.01523566\n",
            "Iteration 188, loss = 0.01359476\n",
            "Iteration 189, loss = 0.01427134\n",
            "Iteration 190, loss = 0.01364275\n",
            "Iteration 191, loss = 0.01349834\n",
            "Iteration 192, loss = 0.01381033\n",
            "Iteration 193, loss = 0.02416718\n",
            "Iteration 194, loss = 0.01534172\n",
            "Iteration 195, loss = 0.01359042\n",
            "Iteration 196, loss = 0.01365780\n",
            "Iteration 197, loss = 0.01320099\n",
            "Iteration 198, loss = 0.01300383\n",
            "Iteration 199, loss = 0.01510607\n",
            "Iteration 200, loss = 0.01315083\n",
            "Iteration 201, loss = 0.01327084\n",
            "Iteration 202, loss = 0.01317972\n",
            "Iteration 203, loss = 0.01294754\n",
            "Iteration 204, loss = 0.01269604\n",
            "Iteration 205, loss = 0.01244911\n",
            "Iteration 206, loss = 0.01217649\n",
            "Iteration 207, loss = 0.01303379\n",
            "Iteration 208, loss = 0.01274542\n",
            "Iteration 209, loss = 0.01291066\n",
            "Iteration 210, loss = 0.01252058\n",
            "Iteration 211, loss = 0.01273898\n",
            "Iteration 212, loss = 0.01253791\n",
            "Iteration 213, loss = 0.01283977\n",
            "Iteration 214, loss = 0.01322968\n",
            "Iteration 215, loss = 0.01297597\n",
            "Iteration 216, loss = 0.01294667\n",
            "Iteration 217, loss = 0.01127808\n",
            "Iteration 218, loss = 0.01210389\n",
            "Iteration 219, loss = 0.01252630\n",
            "Iteration 220, loss = 0.01192715\n",
            "Iteration 221, loss = 0.01199686\n",
            "Iteration 222, loss = 0.01221694\n",
            "Iteration 223, loss = 0.01224870\n",
            "Iteration 224, loss = 0.01236708\n",
            "Iteration 225, loss = 0.01137755\n",
            "Iteration 226, loss = 0.01125762\n",
            "Iteration 227, loss = 0.01177907\n",
            "Iteration 228, loss = 0.01174975\n",
            "Iteration 229, loss = 0.01128538\n",
            "Iteration 230, loss = 0.01133233\n",
            "Iteration 231, loss = 0.01172688\n",
            "Iteration 232, loss = 0.01167275\n",
            "Iteration 233, loss = 0.01110166\n",
            "Iteration 234, loss = 0.01179461\n",
            "Iteration 235, loss = 0.01167365\n",
            "Iteration 236, loss = 0.01130793\n",
            "Iteration 237, loss = 0.01171139\n",
            "Iteration 238, loss = 0.01152386\n",
            "Iteration 239, loss = 0.01277100\n",
            "Iteration 240, loss = 0.01104221\n",
            "Iteration 241, loss = 0.01075199\n",
            "Iteration 242, loss = 0.01055415\n",
            "Iteration 243, loss = 0.01106624\n",
            "Iteration 244, loss = 0.01086835\n",
            "Iteration 245, loss = 0.01074113\n",
            "Iteration 246, loss = 0.01094153\n",
            "Iteration 247, loss = 0.01073346\n",
            "Iteration 248, loss = 0.01032829\n",
            "Iteration 249, loss = 0.01076876\n",
            "Iteration 250, loss = 0.01066225\n",
            "Iteration 251, loss = 0.00984865\n",
            "Iteration 252, loss = 0.00934708\n",
            "Iteration 253, loss = 0.01068909\n",
            "Iteration 254, loss = 0.01052183\n",
            "Iteration 255, loss = 0.01028501\n",
            "Iteration 256, loss = 0.01012796\n",
            "Iteration 257, loss = 0.01073262\n",
            "Iteration 258, loss = 0.01025674\n",
            "Iteration 259, loss = 0.01060390\n",
            "Iteration 260, loss = 0.00995182\n",
            "Iteration 261, loss = 0.01006693\n",
            "Iteration 262, loss = 0.00980727\n",
            "Iteration 263, loss = 0.01002614\n",
            "Training loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='tanh', alpha=1e-07, batch_size=4, beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(8, 5), learning_rate='constant',\n",
              "              learning_rate_init=0.005, max_fun=15000, max_iter=500,\n",
              "              momentum=0.8, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=11, shuffle=True, solver='sgd',\n",
              "              tol=1e-05, validation_fraction=0.2, verbose=True,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w4C6eS9TpA5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "db053987-46c6-4b75-f361-2d3ae23d8815"
      },
      "source": [
        "clf.classes_ "
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBqBrxFkTpA8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0798abad-705a-44b9-eece-ed592899089f"
      },
      "source": [
        "clf.n_layers_ "
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTaTGAbfTpA-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2f839fd5-4f83-4ea5-f207-d0750076e56a"
      },
      "source": [
        "clf.n_outputs_ "
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxa75ozwTpBC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dc46f008-372c-4742-919d-d2e6d8ae0923"
      },
      "source": [
        "clf.out_activation_ "
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'softmax'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Il-Iv-ZmTpBE",
        "colab_type": "text"
      },
      "source": [
        "- 1 input, 2 hidden, 1 ouput: => 4\n",
        "- Thông thường trong Neural Networks, sẽ ko tính input layers, nên  trong Neural Networks, trường hợp này số Layers sẽ là 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOFtjPEWTpBE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "809c1766-e277-482d-b22e-50641683203c"
      },
      "source": [
        "# Evaluate acuracy on test data\n",
        "score = clf.score(X_test_std,y_test)\n",
        "print(\"Acuracy (on test set) = \", score)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acuracy (on test set) =  0.9333333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9xt42YFTpBH",
        "colab_type": "text"
      },
      "source": [
        "- Ta thấy chỉ cần tăng #Layers, #Units độ chính xác sẽ tăng cao"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEpPJEFUTpBI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 44,
      "outputs": []
    }
  ]
}